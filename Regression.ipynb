{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOWOB0To8bljDoMnEwADTOh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OsAouKHEEYtF","executionInfo":{"status":"ok","timestamp":1732450102683,"user_tz":-330,"elapsed":5160,"user":{"displayName":"Harshini V","userId":"05030960265327205852"}},"outputId":"51cbb888-1e3e-4dd0-cad0-c22a9e37c383"},"outputs":[{"output_type":"stream","name":"stdout","text":["Linear reg Accuracy: 0.9253717934621964\n","Logistic reg classification accuracy: 0.9298245614035088\n"]}],"source":["# Regression Both\n","import numpy as np\n","\n","\n","class BaseRegression:\n","    def __init__(self, learning_rate: float = 0.001, n_iters: int = 1000):\n","        # Assign the variables\n","        self.learning_rate = learning_rate\n","        self.n_iters = n_iters\n","\n","        # Weights and bias\n","        self.weights, self.bias = None, None\n","\n","    def fit(self, X, y):\n","        n_samples, n_features = X.shape\n","\n","        self.weights, self.bias = np.zeros(n_features), 0\n","\n","        # Minimizing loss, and finding the correct Weights and biases using Gradient Descent\n","        for _ in range(self.n_iters):\n","            y_predicted = self._approximation(X, self.weights, self.bias)\n","\n","            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n","            db = (1 / n_samples) * np.sum(y_predicted - y)\n","\n","            self.weights -= self.learning_rate * dw\n","            self.bias -= self.learning_rate * db\n","\n","    def predict(self, X):\n","        return self._predict(X, self.weights, self.bias)\n","\n","    def _predict(self, X, w, b):\n","        raise NotImplementedError\n","\n","    def _approximation(self, X, w, b):\n","        raise NotImplementedError\n","\n","\n","class LinearRegression(BaseRegression):\n","    def _approximation(self, X, w, b):\n","        return np.dot(X, w) + b\n","\n","    def _predict(self, X, w, b):\n","        return np.dot(X, w) + b\n","\n","\n","class LogisticRegression(BaseRegression):\n","    def _approximation(self, X, w, b):\n","        linear_model = np.dot(X, w) + b\n","        return self._sigmoid(linear_model)\n","\n","    def _predict(self, X, w, b):\n","        linear_model = np.dot(X, w) + b\n","        y_predicted = self._sigmoid(linear_model)\n","        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n","        return np.array(y_predicted_cls)\n","\n","    def _sigmoid(self, x):\n","        return 1 / (np.exp(-x) + 1)\n","\n","\n","# Testing\n","if __name__ == \"__main__\":\n","    # Imports\n","    from sklearn.model_selection import train_test_split\n","    from sklearn import datasets\n","\n","    # Utils\n","    def r2_score(y_true, y_pred):\n","        corr_matrix = np.corrcoef(y_true, y_pred)\n","        corr = corr_matrix[0, 1]\n","        return corr ** 2\n","\n","    def mean_squared_error(y_true, y_pred):\n","        return np.mean((y_true - y_pred) ** 2)\n","\n","    def accuracy(y_true, y_pred):\n","        accuracy = np.sum(y_true == y_pred) / len(y_true)\n","        return accuracy\n","\n","    # Linear Regression\n","    X, y = datasets.make_regression(\n","        n_samples=100, n_features=1, noise=20, random_state=4\n","    )\n","\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=1234\n","    )\n","\n","    regressor = LinearRegression(learning_rate=0.01, n_iters=1000)\n","    regressor.fit(X_train, y_train)\n","    predictions = regressor.predict(X_test)\n","\n","    accu = r2_score(y_test, predictions)\n","    print(\"Linear reg Accuracy:\", accu)\n","\n","    # Logistic reg\n","    bc = datasets.load_breast_cancer()\n","    X, y = bc.data, bc.target\n","\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=1234\n","    )\n","\n","    regressor = LogisticRegression(learning_rate=0.0001, n_iters=1000)\n","    regressor.fit(X_train, y_train)\n","    predictions = regressor.predict(X_test)\n","\n","    print(\"Logistic reg classification accuracy:\", accuracy(y_test, predictions))"]},{"cell_type":"code","source":[],"metadata":{"id":"NAIVc_IwEnM7"},"execution_count":null,"outputs":[]}]}